| WBS ID | Work Package Name | Description | Deliverables | Resources Assigned | Duration Estimate | Acceptance Criteria |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **1.1.1** | Schedule Kick-off Meeting | Arrange and confirm a date and time for the initial project kick-off meeting. | Confirmed calendar invite sent to the team. | **Nadiah** | **0.5 day (4 hours)** | All core team members confirm attendance. |
| **1.1.2** | Define initial Scope and Goals | Document the high-level boundaries of the project, including the core problem statement. | Initial Scope Statement document. | **Angelo** | **0.5 day (4 hours)** | Scope statement approved by the Project Manager (Angelo). |
| **1.2.1** | Document functional requirements | Identify and formally document what the system must do (e.g., classify 7 emotions, achieve 75% accuracy). | List of Functional Requirements (FRs). | **Qasdina** | **0.5 day (4 hours)** | FRs cover all primary system functions. |
| **1.2.2** | Document non-functional requirements | Identify and formally document system performance constraints (e.g., processing time $\le500$ ms, security). | List of Non-Functional Requirements (NFRs). | **Angelo** | **0.5 day (4 hours)** | NFRs address performance, security, and usability needs. |
| **1.3.1** | Obtain Stakeholder Sign-off | Review the gathered requirements with the project sponsor/client and obtain formal approval. | Requirements document signed/approved by Dr. Farhan Khan. | **Angelo** | **1 day** | Formal acceptance received from Dr. Farhan Khan. |
| **2.1.1** | Identify and select public datasets | Research and select suitable labeled facial expression datasets. | List of potential datasets with licensing and size details. | **Qasdina** | **1 day** | Selection finalized and approved by ML Engineer. |
| **2.2.1** | Download/Extract raw data and labels | Securely download the selected datasets and organize the raw image files and labels. | `/data/raw/` folder containing all downloaded files. | **Nadiah** | **1 day** | Data size meets initial target (e.g., 10,000 images). |
| **2.3.1** | Filter out low-quality/unlabeled images | Inspect and remove corrupted, blurred, or improperly labeled images from the raw set. | Cleaned `/data/cleaned/` folder. | **Qasdina** | **2 days** | Data quality score (or error rate) meets acceptable standard. |
| **2.3.2** | Resize and normalize images | Apply standard preprocessing steps (e.g., resizing to $48\times48$ pixels, pixel value normalization) for model input. | Script for image preprocessing created and tested. | **Angelo** | **1 day** | Preprocessing script runs successfully on sample data. |
| **2.4.1** | Apply transformations (augmentation) | Use techniques like rotation, flipping, and zooming to expand the dataset to $\ge10,000$ labeled images. | `/data/augmented/` folder with final target size. | **Angelo** | **1 day** | Total dataset size reaches the 10,000 labeled image minimum objective. |
| **2.5.1** | Finalize and version control dataset | Split the dataset into training, validation, and test sets, and commit the final metadata. | Versioned `data_split.csv` and final dataset folder structure. | **Qasdina** | **1 day** | Splits are correctly balanced and committed to GitHub. |
| **3.1.1** | Research and select CNN architectures | Study various CNN models and choose a baseline architecture for adaptation. | Document outlining the chosen baseline architecture and justification. | **Angelo** | **1 day** | Selection is based on complexity vs. performance trade-offs. |
| **3.1.2** | Define layer structure and functions | Finalize the specific layer details, filter counts, and activation functions for the custom CNN model. | Model architecture diagram/code structure. | **Angelo** | **1 day** | Model definition matches the required complexity for facial recognition. |
| **3.2.1** | Set up the ML environment | Install necessary libraries and frameworks (Python, TensorFlow/Keras, OpenCV) on the development machine. | Functional virtual environment file (`requirements.txt`). | **Nadiah** | **0.5 day (4 hours)** | All required libraries are installed without dependency conflicts. |
| **3.2.2** | Secure necessary compute resources | Ensure access to GPU or cloud resources required for the heavy model training phase. | Confirmed access/allocation of GPU compute time. | **Nadiah** | **0.5 day (4 hours)** | Compute resources are tested and verified for use. |
| **3.3.1** | Develop and commit initial model code | Write the initial Python code defining the chosen CNN architecture and commit it to GitHub. | `model_architecture.py` committed to the repo. | **Qasdina** | **1 day** | Model code runs without syntax errors and prints a summary. |
| **4.1.1** | Define hyperparameters | Determine optimal values for learning rate, batch size, and the total number of training epochs. | List of training hyperparameters. | **Angelo** | **1 day** | Parameters are chosen based on best practices and initial research. |
| **4.2.1** | Execute initial training run | Train the model for a few epochs on a small subset of the data to test the pipeline and parameters. | Initial training loss/accuracy curves generated. | **Qasdina** | **1 day** | Training pipeline runs successfully without crashing. |
| **4.3.1** | Train the model on the full augmented dataset | Run the main training process using the final dataset and defined hyperparameters. | Final training log detailing loss and validation accuracy per epoch. | **Nadiah** | **3 days** | Training is completed up to the defined epoch count. |
| **4.3.2** | Monitor loss and accuracy metrics | Track and plot the training and validation loss/accuracy to check for overfitting/underfitting. | Graphs of training/validation loss and accuracy over time. | **Qasdina** | **1 day** | Training logs show reasonable convergence. |
| **4.4.1** | Save the best-performing model | Select the model checkpoint with the highest validation accuracy and save it in the required format. | Trained CNN Model File (`.h5` or `.pkl`) committed to the repo. | **Angelo** | **1 day** | Saved model file is verified to load correctly. |
| **5.1.1** | Prepare the dedicated, unseen test dataset | Ensure the test dataset is completely separated from the training/validation sets and correctly formatted. | Final test dataset ready for inference. | **Qasdina** | **0.5 day (4 hours)** | Test data integrity verified. |
| **5.2.1** | Calculate performance metrics | Run the trained model on the test data and calculate accuracy, precision, recall, and F1-score. | Table of key performance metrics. | **Angelo** | **1 day** | All four key metrics (accuracy, precision, recall, F1) are calculated. |
| **5.3.1** | Analyze misclassified images | Identify and document patterns in the images the model failed to classify correctly. | Log of model misclassifications and potential causes. | **Nadiah** | **1 day** | At least 10 misclassified images analyzed. |
| **5.4.1** | Document final performance metrics | Write a concise evaluation summary comparing the results against the target objective of $\ge75\%$ accuracy. | Evaluation Summary document. | **Angelo** | **0.5 day (4 hours)** | Document clearly states whether the $\ge75\%$ accuracy objective was met. |
| **6.1.1** | Create mockups of the classification output | Design the visual layout and user experience (UI/UX) for the prototype application/dashboard. | Wireframes or visual mockups of the user interface. | **Nadiah** | **1 day** | Mockups reviewed and approved by the team. |
| **6.2.1** | Integrate the trained model with application | Build the API endpoint or backend logic that loads the trained model file and handles image input/output. | Backend module capable of returning model predictions. | **Angelo** | **1 day** | Integration successfully loads and makes a prediction on a sample image. |
| **6.3.1** | Code the user interface elements | Implement the front-end components that display the image, the classification result, and prediction certainty. | Functional Prototype Application interface. | **Qasdina** | **1 day** | UI is responsive and accurately reflects the design mockups. |
| **6.4.1** | Finalize the deployable application package | Prepare the prototype for sharing (e.g., containerize it, create an executable, or set up a cloud deployment). | Deployable prototype package. | **Nadiah** | **1 day** | The prototype runs successfully on a separate target environment. |
| **7.1.1** | Test individual components | Conduct unit tests on core modules (data handling, model prediction, dashboard display logic). | Unit test results log. | **Qasdina** | **1 day** | All unit tests pass successfully. |
| **7.2.1** | Test end-to-end classification speed | Measure the system's total processing latency from image input to result display. | Measured latency time recorded. | **Angelo** | **1 day** | Classification time is $\le500$ milliseconds per image. |
| **7.3.1** | Conduct User Acceptance Testing (UAT) | Run the prototype with non-team stakeholders to validate usability and fitness for purpose. | Feedback log from UAT participants. | **Qasdina** | **1 day** | UAT stakeholders sign off on the prototype's usability. |
| **7.4.1** | Record all test results and sign off | Document all testing procedures, findings, and obtain the final team sign-off on system readiness. | Final Testing Documentation. | **Nadiah** | **1 day** | All mandatory tests passed, and documentation is complete. |
| **8.1.1** | Document methodology and results | Write the bulk of the final project report, detailing the methods, results, and challenges. | Draft of the Final Project Report. | **Angelo** | **3 days** | All sections of the report are drafted (Methodology, Results, Conclusion). |
| **8.2.1** | Design slides and talking points | Create the presentation slides and rehearse the content for the stakeholders. | Presentation slide deck. | **Qasdina** | **1 day** | Slides are visually clear and cover all key findings. |
| **8.3.1** | Conduct a team review | Have all team members review the report and presentation for clarity, completeness, and errors. | Log of review comments and corresponding revisions. | **All Team Members** | **1 day** | Report and presentation are free of major errors. |
| **8.4.1** | Deliver final project assets | Finalize all deliverables (model, code, report) and conduct the final presentation. | Final Project Report & Performance Documentation. | **All Team Members** | **1 day** | Final submission is complete and presentation is delivered. |
